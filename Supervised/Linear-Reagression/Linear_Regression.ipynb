{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an example of linear regression\n",
    "## [Reference link from scikit-learn](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic example of Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame( np.array([ [0,.2],[1,0.8],[2,2.2],[3,2.8],[4,4.2],[5,4.8] ]), columns=['x', 'y']  )\n",
    "# df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
    "#                 columns=['a', 'b', 'c'])\n",
    "features = df['x']\n",
    "labels = df['y']\n",
    "plt.scatter(features,labels)\n",
    "x = features.values.reshape(-1,1)\n",
    "y = labels.values.reshape(-1,1)\n",
    "'''\n",
    "so here is the deal with this reshape thing\n",
    "it is used to put your values in the right shape by\n",
    "reshape(row, col)\n",
    "so reshape(-1, 1) \n",
    "-1 for rows because we don't know how many rows there will be\n",
    "1 for columns because we will only have one column\n",
    "'''\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "# this splits our data into training data and testing data\n",
    "# the x is our features \n",
    "# the y is our labels\n",
    "# test_size is how big our test data will be\n",
    "# random_state is making sure that we will always get the same random numbers\n",
    "\n",
    "# in case you want to see anything, just uncomment it below\n",
    "# print('df')\n",
    "# print(df)\n",
    "# print('x\\n',x)\n",
    "# print('y\\n',y)\n",
    "# print('x_train\\n',x_train,'\\nx_test\\n', x_test)\n",
    "# print( 'y_train]\\n',y_train,'\\ny_test\\n', y_test)\n",
    "# >>> reg = linear_model.LinearRegression()\n",
    "# >>> reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])\n",
    "# LinearRegression()\n",
    "# >>> reg.coef_\n",
    "# array([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08571429]\n",
      "[[0.96571429]]\n",
      "[[4.91428571]]\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept_)\n",
    "# the intercept is where model cross the y axis\n",
    "print(model.coef_)\n",
    "# coef is short for coefficient and is a number timesed by the feature to find the label\n",
    "# so for every feature you will have a coefficient\n",
    "# these coefficients are often called weights\n",
    "\n",
    "input_for_prediction = np.array([5]).reshape(-1,1)\n",
    "print(model.predict(input_for_prediction))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:\t 0.9862432073421084\n",
      "mse:\t 0.023248979591836864\n",
      "rmse:\t 0.15247616073287282\n",
      "   predicted  actual\n",
      "0   4.914286     4.8\n",
      "1   2.017143     2.2\n"
     ]
    }
   ],
   "source": [
    "# Testing model\n",
    "print('score:\\t',model.score(x_test,y_test)) # score is accuracy (coefficient of determination (ùëÖ¬≤))\n",
    "y_predicted = model.predict(x_test)\n",
    "mse = mean_squared_error(y_predicted, y_test) # how much the model was off squared\n",
    "print('mse:\\t',mse)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, y_predicted)) # the square root how much the model was off squared\n",
    "print('rmse:\\t', rmse)\n",
    "predicted_vs_actual = pd.DataFrame({'predicted':y_predicted.flatten(), 'actual': y_test.flatten()})\n",
    "print(predicted_vs_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHANE YOU HAVEN'T DONE THIS! IT'S JUST EXAMPLE CODE. \n",
    "# ALSO YOU WHERE ON LOSS AT https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f\n",
    "what the model looks like on training data\n",
    "plot.scatter(xTrain, yTrain, color = 'red')\n",
    "plot.plot(xTrain, linearRegressor.predict(xTrain), color = 'blue')\n",
    "plot.title('Salary vs Experience (Training set)')\n",
    "plot.xlabel('Years of Experience')\n",
    "plot.ylabel('Salary')\n",
    "plot.show()\n",
    "\n",
    "what the model looks like on testing data\n",
    "plot.scatter(xTest, yTest, color = 'red')\n",
    "plot.plot(xTrain, linearRegressor.predict(xTrain), color = 'blue')\n",
    "plot.title('Salary vs Experience (Test set)')\n",
    "plot.xlabel('Years of Experience')\n",
    "plot.ylabel('Salary')\n",
    "plot.show()\n",
    "\n",
    "just another example but only using test\n",
    "plt.scatter(X_test, y_test,  color='gray')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2)\n",
    "plt.show()\n",
    "\n",
    "# example from scikit learn\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "what is r2_score? I saw it on scikit learn @ https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
